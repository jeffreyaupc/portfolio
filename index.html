<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Jeffrey Au's Portfolio</title>
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" 
    integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
    <link rel="stylesheet" media="screen and (min-width: 1200px)" href="css/index.css">
    <link rel="stylesheet" media="screen and (max-width: 1200px)" href="css/smallscreen.css">
    <!-- <link rel="stylesheet" media="screen and (max-width: 1200px)" href="css/midscreen.css"> -->
</head>
<body>
    <div class="topnav">
        <div class='active' href="https://jeffreyaupc.github.io/portfolio/">Welcome to my page!</div>
    </div>
    <div class="feature"><b>About Myself</b></div>
    <div class="selfintro">
        <p>My name is Jeffrey Au, I am a recent graduate in Bachelor of Business Administration with experience in <b>sales</b>, <b>customer service</b> and <b>business administration</b>. 
            Seeking <b>data analyst</b> roles to broaden experience and leverage management skills.
        </p>
        <p>Capable of adapting to new environments and changing priorities to support business demands. 
            6 months experience in data analysis languages including <b>Python</b>, <b>Excel VBA</b>, and <b>PostgreSQL</b>. 
        </p>
        <p>
            The projects below are assignments from the <b>University of Toronto School of Continuing Studies Data Analytics Bootcamp</b> course, where I gained hands-on experience and 
            skills <b>data analysis</b> and <b>visualization</b>. I may also include some personal projects in the future.
        </p>
    </div>
    <div class="feature"><b>Contacts</b></div>
    <div class="contacts">
        <span class="link gmail">
            <a href="mailto:jeffaupc@gmail.com" target="_blank">Gmail</a>
        </span>
        <span class="link linkedin">
            <a href="https://www.linkedin.com/in/jeffrey-au-538567169/" target="_blank">LinkedIn</a>
        </span>
        <span class="link github">
            <a href="https://github.com/jeffreyaupc" target="_blank">Github</a>
        </span>
    </div>
    <div class="feature"><b>Projects</b></div>
    <div class="repos">
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/SDCoulter/final_project" target="_blank"><b>Data Analytics Bootcamp Final Project</b></a><br>
            </p>
            <p class="projectdescription">
                We are setting out to look at how the environment around us affects how happy we are, 
                and how strong this effect is. We will do this by looking at the environmental variables of countries, 
                and seeing if we can use them to predict the Life Ladder target variable from the World Happiness Index.
                <br>
                <b>My role:</b>
                <br>
                I contributed in extracting and cleaning data from multiple sources with Python Pandas using Jupyter notebook, created visualization using Tableau,
                and performed some machine learning prediction using <b>Sklearn linear regression</b> and <b>random forest regressor</b>.
                <br>            
                <b>Technologies:</b> Python (Pandas, Sklearn, Matplotlib), Jupyter Notebook, Tableau
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Neural_Network_Charity_Analysis" target="_blank"><b>Module 19: Neural Network Charity Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this analysis is to help create a <b>binary classifier</b> that is capable of predicting whether applicants will be successful if funded by Alphabet Soup. 
                With a dataset that contains over 34,000 organizations that have received funding from Alphabet Soup over the years, a <b>neural network model</b> is compiled, trained, and evaluated. 
                After that, 3 attempts were made to see if the data or model could be optimized such that it can result in over 75% predictive accuracy.
                <br>
                <b>Technologies:</b> Python (Pandas, Sklearn), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Cryptocurrencies" target="_blank"><b>Module 18: Cryptocurrencies Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this analysis is to classify cryptocurrencies into clusters with different approaches including <b>Principal Component Analysis</b> and <b>K-Means</b>.
                <br>
                <b>Technologies:</b> Python (Pandas, Sklearn, Matplotlib), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Credit_Risk_Analysis" target="_blank"><b>Module 17: Credit Risk Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to resample an unbalanced dataset using <b>oversampling</b>, <b>undersampling</b>, and <b>combination sampling</b> techniques, 
                as well as different classifiers including <b>Balanced Random Forest Classifier</b> and <b>Easy Ensemble Classifier</b> to perform credit risk analysis.
                <br>
                <b>Technologies:</b> Python (Pandas, Sklearn, Imblearn, Matplotlib), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Amazon_Vine_Analysis" target="_blank"><b>Module 16: Amazon Vine Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to perform an <b>ETL</b> process with <b>AWS RDS</b> instance to pgAdmin using <b>PySpark</b>. 
                After that, an analysis is performed to determine if there is any bias toward favorable reviews from Vine members.
                <br>
                <b>Technologies:</b> Python (PySpark), Jupyter Notebook, Amazon AWS RDS, PostgreSQL
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/MechaCar_Statistical_Analysis" target="_blank"><b>Module 15: MechaCar Statistical Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                Performed analysis on MechaCar dataset on multiple aspects vs its competition using Linear Regression, 
                T-Tests, and potentially ANOVA Tests with <b>RStudio</b>.
                <br>
                <b>Technologies:</b> RStudio
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/bikesharing" target="_blank"><b>Module 14: Bike Sharing Program Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this analysis is to convince investors that a bike-sharing program in Desmoines is a solid business proposal.
                <br>
                <b>Technologies:</b> Python (Pandas), Jupyter Notebook, Tableau
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Mapping_Earthquakes" target="_blank"><b>Module 13: Mapping Earthquakes</b></a><br>
            </p>
            <p class="projectdescription">
                Using <b>GeoJSON API calls</b> and Javascript, multiple layers of earthquakes(all earthquakes and only major earthquakes) are mapped. 
                Toronto neighborhoods (polygons), routes (lines) and airports (multiple points) are also mapped.
                <br>
                <b>Technologies:</b> HTML, CSS, JavaScript
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Biodiversity-dashboard" target="_blank"><b>Module 12: Biodiversity Dashboard</b></a><br>
            </p>
            <p class="projectdescription">
                Using <b>Plotly</b>, <b>D3</b> and <b>Bootstrap</b>, an interactive dashboard of biodiversity discovered in people's belly button is created.
                <br>
                <b>Technologies:</b> HTML (Bootstrap), CSS, JavaScript (D3, Plotly)
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/UFOs" target="_blank"><b>Module 11: UFO Sightings</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to allow user filter multiple criteria to search for UFO sightings. 
                For instance, users may add table filters for the date, city, state, country, and shape for their search.
                <br>
                <b>Technologies:</b> HTML (Bootstrap), CSS, Javascript (D3)
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Mission-to-Mars" target="_blank"><b>Module 10: Webscraping: Mars</b></a><br>
            </p>
            <p class="projectdescription">
                Using <b>Splinter</b> and <b>BeautifulSoup</b>, a python application was written to <b>scrape information</b> of Mars from multiple sources and displayed in HTML.
                <br>
                <b>Technologies:</b> Python (Pandas, Splinter, BeautifulSoup), Jupyter Notebook, HTML (Bootstrap)
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/surfs_up" target="_blank"><b>Module 9: Business Analysis: Surf and Ice-cream Shop</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to provide temperature data specifically for the months of June and December in Oahu, 
                in order to determine if the surf and ice cream shop business is sustainable year-round.
                <br>
                <b>Technologies:</b> Python (Pandas, SQLite, Matplotlib), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Movies-ETL" target="_blank"><b>Module 8: Movies ETL</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to create one function that takes in the three files - Wikipedia data, Kaggle metadata, and the MovieLens rating data - 
                and performs the <b>ETL</b> process by adding the data to a <b>PostgreSQL</b> database.
                <br>
                <b>Technologies:</b> Python (Pandas, Numpy, SQLAlchemy), Jupyter Notebook, PostgreSQL
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Pewlett-Hackard-Analysis" target="_blank"><b>Module 7: Pewlett Hackard Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this analysis is to determine the number of retiring employees per title, and identify employees who are eligible to participate in a mentorship program. 
                This analysis helps prepare for Pewlett Hackard's "silver tsunami" as many current employees reach retirement age.
                <br>
                <b>Technologies:</b> PostgreSQL
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/World_Weather_Analysis" target="_blank"><b>Module 6: World Weather Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                Using <b>OpenWeather API calls</b>, the city's location and weather data was <b>extracted</b> into a csv file, 
                which was later used along with <b>Google Map API calls</b> to create a customer travel destination map by filtering desired min and max temperature to find idea hotels in those cities.
                An interactive figure was created within Jupyter Notebook that points out the search results.
                <br>
                <b>Technologies:</b> Python (Pandas), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/PyBer_Analysis" target="_blank"><b>Module 5: Pyber Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of the project is to create a summary dataframe of the ride-sharing data by city type 
                as well as a multiple-line graph that shows the total weekly fares for each city type by analyzing the ride data and city data using Pandas and <b>Matplotlib</b>. 
                Decision-makers at Pyber may make decisions based on how the data differs by city type through the analysis report.
                <br>
                <b>Technologies:</b> Python (Pandas, Matplotlib), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/School_District_Analysis" target="_blank"><b>Module 4: School District Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The students_complete.csv file shows evidence of academic dishonesty; specifically, reading and math grades for Thomas High School ninth grades appear to have been altered. 
                This project is to replace the math and reading scores for Thomas High School with NaNs while keeping the rest of the data intact. 
                The school district analysis is then performed again and a report is written to describe how the changes affects the overall analysis.
                <br>
                <b>Technologies:</b> Python (Pandas), Jupyter Notebook
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/Election_Analysis" target="_blank"><b>Module 3: Election Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to write a Python script that performs an audit for The Colorado Board of Elections' local congressional election. 
                Provided with a CSV file of the election results, the following tasks are to be completed in this project:<br>
                1. Calculate the total number of votes cast.<br>
                2. Get a complete list of candidates who received votes.<br>
                3. Calculate the total number of votes each candidate received.<br>
                4. Calculate the percentage of votes each candidate won.<br>
                5. Determine the winner of the election based on popular vote.<br>
                After completing the audit, the final analysis is saved in a text file.
                <br>
                <b>Technologies:</b> Python
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/VBA_Challenge" target="_blank"><b>Module 2: VBA Challenge</b></a><br>
            </p>
            <p class="projectdescription">
                The Module 2 solution code uses nested for loops to collect data by first looping through the tickers. 
                For each ticker, loop through the rows. If the row's ticker matches the target ticker, it collects and outputs the information, then repeats the process with the next ticker. 
                With 12 tickers, the dataset is looped 12 times, although it works for a dozen stocks, it might not be efficient to run the code for thousands stocks. 
                The purpose of this project is to refactor the Module 2 solution code to loop through all the data one time in order to collect the same information that I did in the module. 
                Therefore, My goal is to refactor the code to make the VBA script more efficient and run faster.
                <br>
                <b>Technologies:</b> Excel (VBA)
            </p>
        </div>
        <div class="repo">
            <p class="projectname">
                <a href="https://github.com/jeffreyaupc/kickstarter-analysis" target="_blank"><b>Module 1: Kickstarter Analysis</b></a><br>
            </p>
            <p class="projectdescription">
                The purpose of this project is to perform an analysis and visualizations on the kickstarter dataset. 
                The analysis and visualization would help Louise understand the relations of how fundraising outcomes would vary based on launch date and based on goals.
                <br>
                <b>Technologies:</b> Excel (Pivot Table)
            </p>
        </div>
    </div>
</body>
</html>
